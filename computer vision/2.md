# Camera Calibration
- Camera calibration is the process of estimating the parameters of a camera to understand how it captures images of the 3D world.
- Why?
    - To correct lens distortions
    - To understand the relationship between 3D world coordinates and 2D image coordinates
    - To enable accurate measurements and 3D reconstructions from images
- It is a mathematical decription of the imaging process, allowinf comp vision to correct distortions, accurately intrpret the scene, and perform measurements.

A Fundamental problem:
- a real camera is nto an ideal pinhole camera
- every camera has:
    - unknown focal length
    - principal point (optical center) not at the image center
    - aspect ratio not equal to 1
    - lens distortions (radial and tangential)
    - sensor gain and offset differences

Essential Parameters:
- Intrinsic Parameters: internal characteristics of the camera. K =
    ```
    fx 0 cx
    0 fy cy
    0 0 1
    ```
    - where:
        - focal length (fx, fy)
        - principal point (cx, cy)
        - radio distortion coefficients (k1, k2, p1, p2, k3)

- Extrinsic Parameters: position and orientation of the camera in the world. [R|t]
- Rotation Orientation Matrix (R): orientation of the camera
- Translation Vector (t): position of the camera
![alt text](image-4.png)
- u & v represent the pixel coordinates in the image plane

Distortion:
- radial distortion: straight lines appear curved
    - becomes larger the farther points are from the image center
    ```
    x_distorted = x * (1 + k1*r^2 + k2*r^4 + k3*r^6)
    y_distorted = y * (1 + k1*r^2 + k2*r^4 + k3*r^6)
    ```
- tangential distortion: occurs when the lens and image plane are not parallel
    ```
    x_distorted = x + [2*p1*x*y + p2*(r^2 + 2*x^2)]
    y_distorted = y + [p1*(r^2 + 2*y^2) + 2*p2*x*y]
    ```
    - where r^2 = x^2 + y^2
    - x, y are the normalized coordinates
    - p1 and p2 are tangential distortion coefficients


Applications of Camera Calibration:
- accurate 3D-to-2D projections
- removal of lens distortions
- improve computer vision algorithms
- calibration in multiple camera systems
- augmented reality

Segmentation:
- task of finding groups of pixels in an image that share certain characteristics
- this problem is also known as cluster analysis
- given an image, the goal is to partition it into segments that are more meaningful and easier to analyze
- binary segmentation: partitioning an image into foreground and background by finding a decision boundary called threshold
- segmentation by humans gestalt:
    - gestalt theory of human perception suggests that humans naturally perceive objects as organized patterns and groups rather than as isolated components.
    - principles of gestalt that are relevant to image segmentation: (order is relevant, higher, more importance)
        - proximity: objects that are close to each other tend to be grouped together
        - similarity: objects that are similar in color, texture, or shape tend to be grouped together
        - common fate: objects with similiar motion or change in appearance belong together
        - common region/connectivity: objects located with connected parts tend to be grouped together
        - continuity: objects that form a continuous pattern tend to be grouped together
        - symmetry: objects that are symmetrical tend to be grouped together, parallel and symmetrical lines are perceived as belonging together
        - illusory contours: the brain tends to perceive complete shapes even when parts are missing
- segmentation techniques:
    - top down segmentation: uses (high level knowledge) prior knowledge sucha s object shapes or class-specific information about the objects to be segmented. pixels belong together if they are part of the same object based on prior knowledge. hard to solve
        - object models guide segmentation + use what we know to guide how pixels are grouped together
        - methods: active contours (snakes), scissors, shape priors, MRF / CRF models, deep learning-based segmentation
        - active contours: start with an initial contour (defined by human) and iteratively deform it to fit object boundaries based on image gradients and smoothness constraints
            - idea is used to srgment using curves and not by pixel
            - a snake is a parametric curve
            - snakes model represents the contour as a parametric curve that evolves over time to minimize an energy function
                - E = E_internal + E_image + E_external
                - E_internal: smoothness and continuity of the contour
                - E_image: attracts curves to edges (strong image gradients)
                - E_external: user constraints or shape bias - remove noises
            - still practical: used in real system when their assumptions hold
                - practical uses cases
                    - medical image segmentation: organ boundary extraction (heart, liver, retina), tumour contour refinement
                    - interactive image segmentation: user provides initial contour, refines segmentation (eg: GrabCut variant)
                    - object tracking: track a known object across frames
                    - industrial inspection: smooth, well defined object boundaries
                    - imp: boundary tracking in video sequences: lip reading (bounday deform over time), car spin (boundary deform over viewpoint changes)
                - in these cases, 
                    - object shape is relatively simple and well defined
                    - edges are strong
                    - intitialization is available
        - scissors: intelligent scissors or live wire is an interactive segmentation technique that allows users to define object boundaries by placing control points along the desired contour. the algorithm then automatically connects these points by finding the optimal path based on image gradients and edge information
            - objects boundaries correspond to strong image gradients, strong edges and avoids flat, textureless regions
            - forumlate segmentation as a shortest path problem in a graph
            - advantages:
                - human high level understanding
                - ...

    - bottom up segmentation: uses local cues such as color, texture, and intensity to group pixels into segments. pixels belong together if they share similar low-level features. can be defined and develop an algorithm. 
        - uses only image evidence
        - methods: thresholding, region growing / merging, mean shift, graph-based segmentation, watershed, normalised cuts
        - pixels -> regions -> larger structures

Graph based segmentation:
- k means 
- mean shift
- graph cut segmentation:
    - represents the image as a graph 
    - segmentation is finding cuts in the graph that minimize a cost function
    - every pixel is a vertex, edges connect neighboring pixels, edge weights represent similarity (eg: color, texture)
    - s(fi, fj) = root(sigma((fik - fjk)^2)) is a pixel dissimilarity function
    - cut c = (va, vb) is a partition of vertices v of graph G = (V, E) into two disjoint subsets Va and Vb
    - cut set: set of edges whose endpoints are in different subsets
    - cost of cut: sum of weights of edges in the cut set
    - cut(va, vb) = sum(w(u, v)) for u in Va, v in Vb
    - criteria for graph cut:
        - a pair of vertices (pixels) within a subgraph should have a high similarity (low cost)
        - a pair of vertices (pixels) in different subgraphs should have a low similarity (high cost)
        - that is, we want to minimize the cost of cut between subgraphs and maximize the similarity within subgraphs
    - accoc(va, v) = sum(w(u, v)) for u in Va, v in V
    - normalized cut: minimise cost of normalized cut, which is the cost of cut divided by the total edge connections to all vertices in the graph
        - Ncut(va, vb) = cut(va, vb) / accoc(va, v) + cut(va, vb) / accoc(vb, v)
        - normalised value should be from 0 to 2
            - near 0: high quality cut, low similarity between subgraphs, high similarity within subgraphs
            - near 2: low quality cut, high similarity between subgraphs, low similarity within subgraphs
        
    - Assume a very small image with 4 pixels, represented as a graph. Pixel (nodes): V = {1, 2, 3, 4}. Edge weights (similarity btw pixels): (large weight = similar, small weight = dissimilar)
        - w(1, 2) = 5
        - w(1, 3) = 1
        - w(2, 3) = 1
        - w(2, 4) = 1
        - w(3, 4) = 5

    - cut(A, B) = 3 as w(1, 3) + w(2, 3) + w(2, 4) = 1 + 1 + 1 = 3
    - assoc(A(1, 2), V) = w(1, 2) + w(1, 3) + w(2, 3) + w(2, 4) = 5 + 1 + 1 + 1 = 8
    - why normalised cut is better than min cut:
        - suppose A = {1}, B = {2, 3, 4}
        - (1, 2) = 5
        - (1, 3) = 1
        - (2, 3) = 1
        - (2, 4) = 1
        - (3, 4) = 5
        - the graph
            ```
            1--5--2
            |   / |
            1  1  1
            | /   |
            3--5--4  
            ```
        - cut(A, B) = 6 as w(1, 2) + w(1, 3) = 5 + 1 = 6
        - assoc(A, V) = w(1, 2) + w(1, 3) = 5 + 1 = 6  
         - assoc(B, V) = 5 + 1 + 1 = 7
        - Ncut(A, B) = cut(A, B) / assoc(A, V) + cut(A, B) / assoc(B, V) = 6/6 + 6/7 = 1 + 0.857 = 1.857
    - edge based segmentation:
    - edge: rapid change in intensity, color, or texture within a small region
        - start with each pixel as a separate segment
        - sort edges by weight (similarity)
        - merge segments connected by edges with low weights (high similarity)
        - stop when a certain threshold is reached or when the desired number of segments is obtained